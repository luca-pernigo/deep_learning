# -*- coding: utf-8 -*-
"""LucaPernigo Assignment4 DL.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ubHYGETsAmrH8FtXULBPUJh1uFRRWJqe
"""

import os
import math
import matplotlib.pyplot as plt
import time
from tqdm import tqdm
import numpy as np

import torch
import torch.nn as nn
from torch.utils.data import Dataset
from torch.utils.data import DataLoader

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
device

class Vocabulary:

    def __init__(self, pad_token="<pad>", unk_token='<unk>', eos_token='<eos>', sos_token='<sos>'):
        self.id_to_string = {}
        self.string_to_id = {}
        
        # add the default pad token
        self.id_to_string[0] = pad_token
        self.string_to_id[pad_token] = 0
        
        # add the default unknown token
        self.id_to_string[1] = unk_token
        self.string_to_id[unk_token] = 1
        
        # add the default unknown token
        self.id_to_string[2] = eos_token
        self.string_to_id[eos_token] = 2   

        # add the default unknown token
        self.id_to_string[3] = sos_token
        self.string_to_id[sos_token] = 3

        # shortcut access
        self.pad_id = 0
        self.unk_id = 1
        self.eos_id = 2
        self.sos_id = 3

    def __len__(self):
        return len(self.id_to_string)

    def add_new_word(self, string):
        self.string_to_id[string] = len(self.string_to_id)
        self.id_to_string[len(self.id_to_string)] = string

    # Given a string, return ID
    # if extend_vocab is True, add the new word
    def get_idx(self, string, extend_vocab=False):
        if string in self.string_to_id:
            return self.string_to_id[string]
        elif extend_vocab:  # add the new word
            self.add_new_word(string)
            return self.string_to_id[string]
        else:
            return self.unk_id


# Read the raw txt file and generate a 1D pytorch tensor
# containing the whole text mapped to sequence of token ID,
# and a vocab file
class ParallelTextDataset(Dataset):

    def __init__(self, src_file_path, tgt_file_path, src_vocab=None,
                 tgt_vocab=None, extend_vocab=False, device='cuda'):
        (self.data, self.src_vocab, self.tgt_vocab,
         self.src_max_seq_length, self.tgt_max_seq_length) = self.parallel_text_to_data(
            src_file_path, tgt_file_path, src_vocab, tgt_vocab, extend_vocab, device)

    def __getitem__(self, idx):
        return self.data[idx]

    def __len__(self):
        return len(self.data)

    def parallel_text_to_data(self, src_file, tgt_file, src_vocab=None, tgt_vocab=None,
                          extend_vocab=False, device='cuda'):
        # Convert paired src/tgt texts into torch.tensor data.
        # All sequences are padded to the length of the longest sequence
        # of the respective file.

        assert os.path.exists(src_file)
        assert os.path.exists(tgt_file)

        if src_vocab is None:
            src_vocab = Vocabulary()

        if tgt_vocab is None:
            tgt_vocab = Vocabulary()
        
        data_list = []
        # Check the max length, if needed construct vocab file.
        src_max = 0
        with open(src_file, 'r') as text:
            for line in text:
                tokens = list(line)
                length = len(tokens)
                if src_max < length:
                    src_max = length

        tgt_max = 0
        with open(tgt_file, 'r') as text:
            for line in text:
                tokens = list(line)
                length = len(tokens)
                if tgt_max < length:
                    tgt_max = length
        tgt_max += 2  # add for begin/end tokens
                    
        src_pad_idx = src_vocab.pad_id
        tgt_pad_idx = tgt_vocab.pad_id

        tgt_eos_idx = tgt_vocab.eos_id
        tgt_sos_idx = tgt_vocab.sos_id

        # Construct data
        src_list = []
        print(f"Loading source file from: {src_file}")
        with open(src_file, 'r') as text:
            for line in tqdm(text):
                seq = []
                tokens = list(line)
                for token in tokens:
                    seq.append(src_vocab.get_idx(token, extend_vocab=extend_vocab))
                var_len = len(seq)
                var_seq = torch.tensor(seq, device=device, dtype=torch.int64)
                # padding
                new_seq = var_seq.data.new(src_max).fill_(src_pad_idx)
                new_seq[:var_len] = var_seq
                src_list.append(new_seq)

        tgt_list = []
        print(f"Loading target file from: {tgt_file}")
        with open(tgt_file, 'r') as text:
            for line in tqdm(text):
                seq = []
                tokens = list(line)
                # append a start token
                seq.append(tgt_sos_idx)
                for token in tokens:
                    seq.append(tgt_vocab.get_idx(token, extend_vocab=extend_vocab))
                # append an end token
                seq.append(tgt_eos_idx)

                var_len = len(seq)
                var_seq = torch.tensor(seq, device=device, dtype=torch.int64)

                # padding
                new_seq = var_seq.data.new(tgt_max).fill_(tgt_pad_idx)
                new_seq[:var_len] = var_seq
                tgt_list.append(new_seq)

        # src_file and tgt_file are assumed to be aligned.
        assert len(src_list) == len(tgt_list)
        for i in range(len(src_list)):
            data_list.append((src_list[i], tgt_list[i]))

        print("Done.")
            
        return data_list, src_vocab, tgt_vocab, src_max, tgt_max

# `DATASET_DIR` should be modified to the directory where you downloaded the dataset.
DATASET_DIR = "/content/"

TRAIN_FILE_NAME = "train"
VALID_FILE_NAME = "interpolate"

INPUTS_FILE_ENDING = ".x"
TARGETS_FILE_ENDING = ".y"

TASK = "numbers__place_value"
#TASK = "comparison__sort"
# TASK = "algebra__linear_1d"

# Adapt the paths!

src_file_path = f"{DATASET_DIR}/{TASK}/{TRAIN_FILE_NAME}{INPUTS_FILE_ENDING}"
tgt_file_path = f"{DATASET_DIR}/{TASK}/{TRAIN_FILE_NAME}{TARGETS_FILE_ENDING}"

train_set = ParallelTextDataset(src_file_path, tgt_file_path, extend_vocab=True)

# get the vocab
src_vocab = train_set.src_vocab
tgt_vocab = train_set.tgt_vocab

src_file_path = f"{DATASET_DIR}/{TASK}/{VALID_FILE_NAME}{INPUTS_FILE_ENDING}"
tgt_file_path = f"{DATASET_DIR}/{TASK}/{VALID_FILE_NAME}{TARGETS_FILE_ENDING}"

valid_set = ParallelTextDataset(
    src_file_path, tgt_file_path, src_vocab=src_vocab, tgt_vocab=tgt_vocab,
    extend_vocab=False)

batch_size = 64

train_data_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)

valid_data_loader = DataLoader(dataset=valid_set, batch_size=batch_size, shuffle=False)

src_vocab.id_to_string

tgt_vocab.id_to_string

########
# Taken from:
# https://pytorch.org/tutorials/beginner/transformer_tutorial.html
# or also here:
# https://github.com/pytorch/examples/blob/master/word_language_model/model.py
class PositionalEncoding(nn.Module):

    def __init__(self, d_model, dropout=0.0, max_len=5000):
        super(PositionalEncoding, self).__init__()
        self.dropout = nn.Dropout(p=dropout)
        self.max_len = max_len

        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float()
                             * (-math.log(10000.0) / d_model))
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        pe = pe.unsqueeze(0).transpose(0, 1)  # shape (max_len, 1, dim)
        self.register_buffer('pe', pe)  # Will not be trained.

    def forward(self, x):
        """Inputs of forward function
        Args:
            x: the sequence fed to the positional encoder model (required).
        Shape:
            x: [sequence length, batch size, embed dim]
            output: [sequence length, batch size, embed dim]
        """
        assert x.size(0) < self.max_len, (
            f"Too long sequence length: increase `max_len` of pos encoding")
        # shape of x (len, B, dim)
        x = x + self.pe[:x.size(0), :]
        return self.dropout(x)

class TransformerModel(nn.Module):   
    
    def __init__(self,src_vocab_size, tgt_vocab_size, max_len, dropout, device, d_model=256, src_pad_idx=0,
        encoder_layers=3, decoder_layers=2, dim_feedforward=1024, num_heads=8):  


        
        super().__init__()
        self.src_pad_idx = src_pad_idx

        self.d_model = d_model      
        self.embedding_src = nn.Embedding(src_vocab_size, d_model)
        self.embedding_tgt = nn.Embedding(tgt_vocab_size, d_model)

        self.pos_encoder = PositionalEncoding(d_model, dropout, max_len) 

        encoder_layer = nn.TransformerEncoderLayer(d_model, num_heads, dim_feedforward, dropout)
        encoder_norm = nn.LayerNorm(d_model)
        self.encoder = nn.TransformerEncoder(encoder_layer, encoder_layers, encoder_norm)

        decoder_layer = nn.TransformerDecoderLayer(d_model, num_heads, dim_feedforward, dropout)
        decoder_norm = nn.LayerNorm(d_model)
        self.decoder = nn.TransformerDecoder(decoder_layer, decoder_layers, decoder_norm)
        self.transformer = nn.Transformer(d_model, num_heads, encoder_layers, decoder_layers, dim_feedforward)

        self.linear = nn.Linear(d_model, tgt_vocab_size)
        self.device = device
        


    
    def create_src_padding_mask(self, src):    
        src_padding_mask = src.transpose(0,1) == self.src_pad_idx 
        return src_padding_mask.to(self.device)


    def create_tgt_padding_mask(self, tgt):    
        tgt_padding_mask = tgt.transpose(0,1) == self.src_pad_idx  
        return tgt_padding_mask.to(self.device)


    def memory_key_padding_mask(self, memory):   
        memory_padding_mask = memory.transpose(0,1) == self.src_pad_idx  
        return memory_padding_mask.to(self.device)




    def forward(self, src, tgt): 
        """Forward function.

        Parameters:
          src: tensor of shape (sequence_length, batch, data dim)
          tgt: tensor of shape (sequence_length, batch, data dim)
        Returns:
          tensor of shape (sequence_length, batch, data dim)
        """

        src = src.transpose(0, 1).to(device)
        tgt = tgt.transpose(0, 1).to(device)

       
        src_key_padding_mask = self.create_src_padding_mask(src).to(device)
        tgt_key_padding_mask = self.create_tgt_padding_mask(tgt).to(device)  
        memory_padding_mask = self.memory_key_padding_mask(src) 
        tgt_mask = self.transformer.generate_square_subsequent_mask(tgt.shape[0]).to(device) 
       
        tgt = self.embedding_tgt(tgt)
        tgt = self.pos_encoder(tgt)
        out = self.embedding_src(src)
        out = self.pos_encoder(out)
        
        out = self.transformer(
            out, tgt, tgt_mask=tgt_mask,
            src_key_padding_mask = src_key_padding_mask, 
            tgt_key_padding_mask = tgt_key_padding_mask,
            memory_key_padding_mask = memory_padding_mask
            )
        out = out.view(-1, self.d_model)
        out = self.linear(out)  

        return out

    def forward_separate(self, src, tgt):

        src = src.transpose(0, 1).to(device)
        tgt = tgt.transpose(0, 1).to(device)

        src_key_padding_mask = self.create_src_padding_mask(src).to(device)
        tgt_key_padding_mask = self.create_tgt_padding_mask(tgt).to(device)
        memory_key_padding_mask = src_key_padding_mask
        tgt_mask = nn.Transformer.generate_square_subsequent_mask(tgt.shape[0]).to(device)

        tgt = self.embedding_tgt(tgt)
        tgt = self.pos_encoder(tgt)
        out = self.embedding_src(src)
        out = self.pos_encoder(out)

        out = self.encoder(out, src_key_padding_mask=src_key_padding_mask)
        tgt = self.decoder(tgt, tgt_mask=tgt_mask, tgt_key_padding_mask=tgt_key_padding_mask,
            memory_key_padding_mask=memory_key_padding_mask)
        
        out = out.view(-1, self.d_model)
        out = self.linear(out)
        return out


def greedy_search(steps, src_greedy, tgt_greedy):
  model.eval()
  
  #forward encoder one time
  src_greedy = src_greedy.transpose(0, 1).to(device)
  emb_input = model.embedding_src(src_greedy)
  enc_input = model.pos_encoder(emb_input)
  enc_output = model.transformer.encoder.forward(enc_input)
  
  len_tgt_greedy = tgt_greedy.size(0)
  dec_seq = torch.zeros(len_tgt_greedy).to(device)
  dec_seq = dec_seq.reshape(1, len_tgt_greedy).to(device)
  sos = tgt_vocab.string_to_id['<sos>']
  eos = tgt_vocab.string_to_id['<eos>']
  pad = tgt_vocab.string_to_id['<pad>']
  dec_seq = dec_seq.masked_fill(dec_seq == 0, sos)

  #forward decoder multiple times
  for i in range(1, steps):
    emb_input = model.embedding_tgt(dec_seq.long()).to(device)
    enc_input = model.pos_encoder(emb_input)
    dec_output = model.transformer.decoder.forward(enc_input, enc_output)
    out = model.linear(dec_output)
    max_out = torch.max(out, dim=-1, keepdim=True)
    predicted = max_out[1][-1, :, :].to(device)
  
    predicted = predicted.reshape(1, dec_seq.size(1))
    dec_seq = torch.cat([dec_seq, predicted]).to(device)
    
    if predicted.transpose(0 ,1)[-1,-1]==eos:
      break
      
  greedy=dec_seq
  

  colunms = greedy.size(1)
  rows = greedy.size(0)
  for column in range(colunms):
    for row in range(rows):
      if greedy[row, column] == eos:
        for r_pad in range(row+1, rows):
          greedy[r_pad, column] = pad

  return greedy

      

def accuracy(model, data_loader, loss_fn, device):
  correct=0
  accumulate_loss=0
  step = 0
  total=0

  for batch in iter(data_loader):
    src = batch[0]  
    tgt = batch[1]
    enc_input = src.to(device)
    dec_input = tgt[:, : -1].to(device)
    output = model(enc_input, dec_input) 
    lab_dec = tgt[:, 1:].to(device)
    lab_dec = lab_dec.transpose(0, 1).flatten().to(device)

    loss = loss_fn(output, lab_dec)
    accumulate_loss = accumulate_loss+loss.item()
    total = total+tgt.size(0)

    _, predicted = output.max(1)
    predicted = predicted.view(-1, tgt.size(0))
    lab_dec = lab_dec.view(-1, tgt.size(0))

    tgt_len = tgt.size(0)
    for i in range(tgt_len):
      #if all entries are equal then it is correct
      num_correct = torch.sum(lab_dec[:, i] == predicted[:, i])
      if num_correct == tgt.size(1)-1:
        correct = 1+correct
    step = 1+step

  return accumulate_loss, step, correct, total

src_vocab_size, tgt_vocab_size = len(src_vocab), len(tgt_vocab)
max_len=5000
dropout=0

d_model= 256 
num_heads=8
encoder_layers=3 
decoder_layers = 2
dim_feedforward = 1024

src_pad_idx = src_vocab.string_to_id["<pad>"]
tgt_pad_idx= tgt_vocab.string_to_id["<pad>"]

lr = 0.0001 
num_epochs=10
batch_size= 64
n_batches=1000
k_steps = 10

model = TransformerModel(src_vocab_size, tgt_vocab_size, max_len, dropout, device, d_model, src_pad_idx,
                         encoder_layers, decoder_layers, dim_feedforward, num_heads).to(device)

optimizer = torch.optim.Adam(model.parameters(), lr)
loss_fn = nn.CrossEntropyLoss(ignore_index = tgt_pad_idx) 

list_train_loss, list_val_loss, list_train_acc, list_val_acc = [], [], [], []

for epoch in range(num_epochs):
  
  for i, batch in enumerate(iter(train_data_loader)):
    model.train()
    src = batch[0]  
    tgt = batch[1]
    enc_input = src.to(device)
    dec_input = tgt[:, : -1].to(device)
    output = model(enc_input, dec_input)
    
    lab_dec = tgt[:, 1:].to(device)
    lab_dec = lab_dec.transpose(0, 1).flatten().to(device)
    loss = loss_fn(output, lab_dec)

    if i % k_steps == 0:                 
      optimizer.zero_grad()
      loss.backward()
      torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm = 0.1) 
      optimizer.step()


  model.eval()
  with torch.no_grad():
    train_accumulate_loss, train_step, train_correct, train_total = accuracy(model, train_data_loader, loss_fn, device)
    train_loss = train_accumulate_loss/train_step
    train_acc = 100*train_correct/train_total
    list_train_loss.append(train_loss)
    list_train_acc.append(train_acc)
    print("num epoch:", epoch, ", step:", i, ", training loss:", train_loss, ", training accuracy:", train_acc)

  model.eval()
  with torch.no_grad():
    val_accumulate_loss, val_step, val_correct, val_total = accuracy(model, valid_data_loader, loss_fn, device)
    val_loss = val_accumulate_loss/val_step
    val_acc = 100*val_correct/val_total
    print("num epoch:", epoch, ", step:", i, ", validation loss:", val_loss, ", validation accuracy:", val_acc)
    list_val_loss.append(val_loss)  
    list_val_acc.append(val_acc)

epochs=np.arange(10)
plt.plot(epochs, list_train_loss, marker="o", markerfacecolor="blue", markersize=4, color="blue", linewidth=2, label="training")
plt.plot(epochs, list_val_loss, marker="o", markerfacecolor="red", markersize=4, color="red", linewidth=2, label="validation")


plt.xticks(epochs)
plt.title("Training vs Validation Loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()

plt.plot(epochs, list_train_acc, marker="o", markerfacecolor="blue", markersize=4, color="blue", linewidth=2, label="training")
plt.plot(np.arange(10), list_val_acc, marker="o", markerfacecolor="red", markersize=4, color="red", linewidth=2, label="validation")
extraticks=[70, 80]
plt.xticks(epochs)
plt.yticks(list(plt.yticks()[0])+ extraticks)

plt.hlines(90, 0, epochs[-1], linestyle="dashed",colors='black')

plt.title("Training vs Validation Accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()

for batch in valid_data_loader:
  src = batch[0]  
  tgt = batch[1]
  src_greedy = src[1: 25, :]
  tgt_greedy = tgt[1: 25, :]
  break

steps = tgt_greedy.size(1)
predicted = greedy_search(
    steps, 
    src_greedy, tgt_greedy
)
predicted = predicted.transpose(0 ,1)

new_src_dict = {v: k for k, v in src_vocab.string_to_id.items()}
new_tgt_dict = {v: k for k, v in tgt_vocab.string_to_id.items()}

for i in range(24):
  print('\n')
  print(f"Question {i + 1}:")
  question = []
  for char in range(src_greedy.size(1)):
    question.append(new_src_dict[src_greedy[i, char].item()])
  print(''.join(question))
  print('\n')
  print("Generated answer:")
  gen = []
  for char in range(predicted.size(1)):
    gen.append(new_tgt_dict[predicted[i, char].item()])
  print(''.join(gen))
  print('\n')

  print("Expected answer:")
  answer = []
  for j in range(tgt_greedy.size(1)):
    answer.append(new_tgt_dict[tgt_greedy[i, j].item()])
  print(''.join(answer))