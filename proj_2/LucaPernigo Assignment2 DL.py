# -*- coding: utf-8 -*-
"""LucaPernigo Assignment2 DL.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PtXWnKhAhq6djyT3Cu8eR1FoQh1l7ZIk
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms

import numpy as np
import matplotlib.pyplot as plt

import math

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

device

# for training:
batch_size = 32
learning_rate = 0.001
momentum = 0.9

#1.1.1 Load the dataset
train_set = torchvision.datasets.CIFAR10(
    root='./data', train=True, transform=transforms.ToTensor(), download=True)

test_set = torchvision.datasets.CIFAR10(
    root='./data', train=False,transform=transforms.ToTensor())

# Dataloaders
test_loader = torch.utils.data.DataLoader(
    dataset=test_set, batch_size=batch_size, shuffle=False)

#1.1.1 Number of images check
print(train_set)
print(test_set)

#we do that transpose to get the right shape for plt imshow
print(np.shape(train_set[13][0].numpy()))
print(np.shape(train_set[13][0].numpy().transpose(1,2,0)))

#1.1.1 Visualize four images from training set
plt.imshow(np.squeeze((train_set[24532][0].numpy().transpose(1,2,0))))
plt.imshow(np.squeeze((train_set[5][0].numpy().transpose(1,2,0))))
plt.imshow(np.squeeze((train_set[27][0].numpy().transpose(1,2,0))))
plt.imshow(np.squeeze((train_set[1935][0].numpy().transpose(1,2,0))))

#number of images
#np.shape(train_set)

#1.1.2 Value normalization for each channel
train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=False, transform=transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.4915, 0.4823, 0.4468),
                         (0.2470, 0.2435, 0.2616))
]))



test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=False, transform=transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.4915, 0.4823, 0.4468),
                         (0.2470, 0.2435, 0.2616))
]))



test_loader = torch.utils.data.DataLoader(
    dataset=test_set, batch_size=batch_size, shuffle=False)

#print(train_set)

#1.1.3 Check means and stds

train_set.data.shape

print(np.mean(train_set.data[:,:,:,0])/255,
np.mean(train_set.data[:,:,:,1])/255,
np.mean(train_set.data[:,:,:,2])/255)

print(np.std(train_set.data[:,:,:,0])/255,
np.std(train_set.data[:,:,:,1])/255,
np.std(train_set.data[:,:,:,2])/255)

#1.1.4
#Weigth Random sampler

train_sampler = torch.utils.data.WeightedRandomSampler([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1], 49000, replacement=False)
valid_sampler = torch.utils.data.WeightedRandomSampler([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1], 1000, replacement=False)

train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,
                                          sampler=train_sampler, num_workers=2)

valid_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,
                                          sampler=valid_sampler, num_workers=2)

print(len(train_sampler))
print(len(valid_sampler))

#SubsetRandomSampler

idx = np.arange(len(train_set))

# Use last 1000 images for validation
val_indices = idx[49000:]
train_indices= idx[:49000]

print(len(val_indices))
print(len(train_indices))

train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)
valid_sampler = torch.utils.data.SubsetRandomSampler(val_indices)

train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,
                                          sampler=train_sampler, num_workers=2)

valid_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,
                                          sampler=valid_sampler, num_workers=2)

print(len(train_sampler))
print(len(valid_sampler))

#1.2.1


class CNN(nn.Module):
  def __init__(self):
    super(CNN, self).__init__()
    self.conv1 = nn.Conv2d(3, 32, 3)
    self.conv2 = nn.Conv2d(32, 32, 3)
    self.conv3 = nn.Conv2d(32, 64, 3)
    self.conv4 = nn.Conv2d(64, 64, 3)
    

    self.pool = nn.MaxPool2d((2,2), stride=(2,2))
    
    #1.3.5 dropout
    self.dropout=nn.Dropout(0.2)

    self.fc1 = nn.Linear(64*5*5, 512)
    self.fc2 = nn.Linear(512, 10)
   


  def forward(self, x):
    x = F.relu(self.conv1(x))
    x = F.relu(self.conv2(x))
    x = self.pool(x)

    #1.3.5 dropout
    x = self.dropout(x)

    x = F.relu(self.conv3(x))
    x = F.relu(self.conv4(x))
    x = self.pool(x)

    #1.3.5 dropout
    x = self.dropout(x)

    x = x.view(-1,64*5*5 )
    x = F.relu(self.fc1(x))
    x = self.fc2(x)
    return x

        
learning_rate=0.001

model = CNN()
print(model)

model = model.to(device)

loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)

#1.3.7


class CNN(nn.Module):
  def __init__(self):
    super(CNN, self).__init__()
    self.conv1 = nn.Conv2d(3, 32, 3, padding=(1,1))
    self.conv2 = nn.Conv2d(32, 32, 3, padding=(1,1))
    self.conv3 = nn.Conv2d(32, 64, 3, padding=(1,1))
    self.conv4 = nn.Conv2d(64, 64, 3, padding=(1,1))
    self.conv5 = nn.Conv2d(64, 128, 3, padding=(1,1)) 
    self.conv6 = nn.Conv2d(128, 128, 3, padding=(1,1))   
    self.conv7 = nn.Conv2d(128, 256, 3, padding=(1,1)) 
    self.conv8 = nn.Conv2d(256, 256, 3, padding=(1,1))   
    self.pool = nn.MaxPool2d((2,2), stride=(2,2))

    self.dropout=nn.Dropout(0.2)

    self.fc1=nn.Linear(2*2*256, 512)
    self.fc2=nn.Linear(512, 10)


  def forward(self, x):
    x = F.relu(self.conv1(x))
    x = F.relu(self.conv2(x))
    x = self.pool(x)
    x = self.dropout(x)

    x = F.relu(self.conv3(x))
    x = F.relu(self.conv4(x))
    x = self.pool(x)
    x = self.dropout(x)

    x = F.relu(self.conv5(x))
    x = F.relu(self.conv6(x))
    x = self.pool(x)
    x = self.dropout(x)

    x = F.relu(self.conv7(x))
    x = F.relu(self.conv8(x)) 
    x = self.pool(x)
    x = self.dropout(x) 

    x = x.view(-1, 256*2*2)
    
    x = F.relu(self.fc1(x))
    x = self.fc2(x)
    return x


model = CNN()
print(model)

model = model.to(device)

learning_rate=0.005

loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)

#print(model)


#1.3.1
#num_epochs used were 20 for points from 1.2.1 to 1.3.6, 
#and num_epochs used were 25 for point 1.3.7

#num_epochs=20
num_epochs = 25
validations_acc={}
training_acc={}
training_loss=list()
val_loss=list()

for epoch in range(1, num_epochs):
    running_loss = 0.0
    running_total = 0
    running_correct = 0
    run_step = 0


    for i, (images, labels) in enumerate(train_loader, 0):
        model.train() 
        images = images.to(device) 
        labels = labels.to(device)  
        outputs = model(images) 
        loss = loss_fn(outputs, labels)
        optimizer.zero_grad()  
        loss.backward()  
        optimizer.step()

        running_loss += loss.item()
        running_total += labels.size(0)

        with torch.no_grad():
            _, predicted = outputs.max(1)
        running_correct += (predicted == labels).sum().item()
        run_step += 1
        if i % 200 == 0:
            # check accuracy.
            print(f'epoch: {epoch}, steps: {i}, '
                  f'train_loss: {running_loss / run_step :.3f}, '
                  f'running_acc: {100 * running_correct / running_total:.1f} %')
            running_loss = 0.0
            running_total = 0
            running_correct = 0
            run_step = 0
    training_acc[epoch]=(100*running_correct/running_total)
    training_loss.append(loss.item())
          

    # validation
    correct = 0
    total = 0
    model.eval()
    with torch.no_grad():
        for data in valid_loader:
            images, labels = data
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss=loss_fn(outputs, labels)
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
            val_acc = 100 * correct / total

        val_loss.append(loss.item())



    print(f'Validation accuracy: {100 * correct / total: .1f} %')
    
    validations_acc[epoch]=val_acc

print('Finished Training')

# Evaluation
with torch.no_grad():
    correct = 0
    total = 0
    model.eval() 
    for data in test_loader:
        images, labels = data
        
        images = images.to(device)
        labels = labels.to(device) 
        outputs = model(images) 
        _, predicted = outputs.max(dim=1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
    test_acc = 100 * correct / total
    print(f'Test accuracy: {test_acc} %')
    print(f'Test error rate: {100 - 100 * correct / total: .2f} %')

maximum = max(validations_acc, key=validations_acc.get)
print(maximum, validations_acc[maximum])

#1.3.4
epochs, val_acc = zip(*validations_acc.items()) 
epochs, tra_acc = zip(*training_acc.items()) 

plt.plot(epochs, val_acc, marker="o", markerfacecolor="red", markersize=4, color="red", linewidth=2, label="validation")
plt.plot(epochs, tra_acc, marker="o", markerfacecolor="blue", markersize=4, color="blue", linewidth=2, label="training")

extraticks=[70, 80]
plt.xticks(epochs)
plt.yticks(list(plt.yticks()[0])+ extraticks)

#plt.hlines(80, 0, epochs[-1], linestyle="dashed",colors='black')
plt.title("Training vs Validation Accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

plt.plot(epochs, training_loss, marker="o", markerfacecolor="blue", markersize=4, color="blue", linewidth=2, label="training")
plt.plot(epochs, val_loss, marker="o", markerfacecolor="red", markersize=4, color="red", linewidth=2, label="validation")

plt.xticks(epochs)
plt.title("Training vs Validation Loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()
plt.show()


#1.3.6
valid_dataiter = iter(valid_loader)

classes = ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')

valid_images, valid_labels = next(valid_dataiter)

with torch.no_grad():
    model.eval() 
    
    model.eval()
    i=12
    images = valid_images[i].to(device)
    labels = classes[valid_labels[i]]
    
    outputs = model(images) 
    _, predicted = outputs.max(dim=1)
    
    
    #prepare data for plotting
    images[0,:,:]=images.data[0,:,:]*0.247+0.4914
    images[1,:,:]=images.data[1,:,:]*0.243+0.4822
    images[2,:,:]=images.data[2,:,:]*0.261+0.4465

    plt.imshow(np.squeeze((images.to("cpu").numpy().transpose(1,2,0))))
  
    #trasform logit unnormalized log probabilities to probabilities
    outputs=torch.exp(outputs)
    outputs=outputs/torch.sum(outputs)
    print(outputs)
    print(labels)
    print(classes[predicted])